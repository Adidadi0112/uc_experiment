{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Synthetic Data Generation\n",
                "\n",
                "This notebook standardized imputed data and then generates synthetic data using CTGAN, TVAE, and ADASYN for each of the imputed datasets (MICE, KNN, SoftImpute, GAIN).\n",
                "Results are saved in `data/synthetic/{imputation_method}/`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sdv.single_table import CTGANSynthesizer, TVAESynthesizer\n",
                "from sdv.metadata import SingleTableMetadata\n",
                "from imblearn.over_sampling import ADASYN\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import os\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings(\"ignore\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "imputation_methods = ['mice', 'knn', 'softimpute', 'gain', 'pmm']\n",
                "target_col = 'mayo' # Target column for ADASYN oversampling\n",
                "\n",
                "# Ensure base directory exists\n",
                "os.makedirs('../data/synthetic', exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "generation_loop",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "========================================\n",
                        "Processing Imputation Method: MICE\n",
                        "========================================\n",
                        "Data loaded: (252, 56)\n",
                        "  > Standardizing data...\n",
                        "    Data standardized.\n",
                        "  > Generating CTGAN for mice...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Gen. (-3.79) | Discrim. (-0.30): 100%|██████████| 300/300 [00:36<00:00,  8.14it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    CTGAN Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating TVAE for mice...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loss: -62.697: 100%|██████████| 300/300 [00:13<00:00, 21.54it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    TVAE Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating ADASYN for mice...\n",
                        "    ADASYN Saved (Standardized -> Generated -> Inverse Transformed). New shape: (340, 56)\n",
                        "\n",
                        "========================================\n",
                        "Processing Imputation Method: KNN\n",
                        "========================================\n",
                        "Data loaded: (252, 56)\n",
                        "  > Standardizing data...\n",
                        "    Data standardized.\n",
                        "  > Generating CTGAN for knn...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Gen. (-3.96) | Discrim. (-0.25): 100%|██████████| 300/300 [00:36<00:00,  8.29it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    CTGAN Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating TVAE for knn...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loss: -51.820: 100%|██████████| 300/300 [00:14<00:00, 21.19it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    TVAE Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating ADASYN for knn...\n",
                        "    ADASYN Saved (Standardized -> Generated -> Inverse Transformed). New shape: (351, 56)\n",
                        "\n",
                        "========================================\n",
                        "Processing Imputation Method: SOFTIMPUTE\n",
                        "========================================\n",
                        "Data loaded: (252, 56)\n",
                        "  > Standardizing data...\n",
                        "    Data standardized.\n",
                        "  > Generating CTGAN for softimpute...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Gen. (-4.44) | Discrim. (0.42): 100%|██████████| 300/300 [00:35<00:00,  8.48it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    CTGAN Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating TVAE for softimpute...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loss: -62.924: 100%|██████████| 300/300 [00:13<00:00, 21.46it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    TVAE Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating ADASYN for softimpute...\n",
                        "    ADASYN Saved (Standardized -> Generated -> Inverse Transformed). New shape: (346, 56)\n",
                        "\n",
                        "========================================\n",
                        "Processing Imputation Method: GAIN\n",
                        "========================================\n",
                        "Data loaded: (252, 56)\n",
                        "  > Standardizing data...\n",
                        "    Data standardized.\n",
                        "  > Generating CTGAN for gain...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Gen. (-4.77) | Discrim. (-0.26): 100%|██████████| 300/300 [00:35<00:00,  8.41it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    CTGAN Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating TVAE for gain...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loss: -54.350: 100%|██████████| 300/300 [00:14<00:00, 21.24it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    TVAE Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating ADASYN for gain...\n",
                        "    ADASYN Saved (Standardized -> Generated -> Inverse Transformed). New shape: (351, 56)\n",
                        "\n",
                        "========================================\n",
                        "Processing Imputation Method: PMM\n",
                        "========================================\n",
                        "Data loaded: (252, 56)\n",
                        "  > Standardizing data...\n",
                        "    Data standardized.\n",
                        "  > Generating CTGAN for pmm...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Gen. (-4.66) | Discrim. (0.72): 100%|██████████| 300/300 [00:36<00:00,  8.24it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    CTGAN Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating TVAE for pmm...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Loss: -43.910: 100%|██████████| 300/300 [00:14<00:00, 20.64it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "    TVAE Saved (Standardized -> Generated -> Inverse Transformed).\n",
                        "  > Generating ADASYN for pmm...\n",
                        "    ADASYN Saved (Standardized -> Generated -> Inverse Transformed). New shape: (347, 56)\n",
                        "\n",
                        "All synthetic data generation tasks completed.\n"
                    ]
                }
            ],
            "source": [
                "for method in imputation_methods:\n",
                "    print(f\"\\n{'='*40}\\nProcessing Imputation Method: {method.upper()}\\n{'='*40}\")\n",
                "    \n",
                "    input_path = f'../data/processed/uc_diagnostic_tests_{method}.csv'\n",
                "    if not os.path.exists(input_path):\n",
                "        print(f\"File not found: {input_path} -- Skipping.\")\n",
                "        continue\n",
                "        \n",
                "    df = pd.read_csv(input_path)\n",
                "    print(f\"Data loaded: {df.shape}\")\n",
                "    \n",
                "    # --- STANDARDIZATION ---\n",
                "    print(\"  > Standardizing data...\")\n",
                "    \n",
                "    # Separate features and target\n",
                "    if target_col in df.columns:\n",
                "        X = df.drop(columns=[target_col])\n",
                "        y = df[target_col]\n",
                "    else:\n",
                "        X = df\n",
                "        y = None\n",
                "        \n",
                "    # Apply StandardScaler to Features\n",
                "    scaler = StandardScaler()\n",
                "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
                "    \n",
                "    # Recombine for SDV (SDV learns joint distribution)\n",
                "    if y is not None:\n",
                "        # Reset indices to avoid mismatch during concat\n",
                "        X_scaled.reset_index(drop=True, inplace=True)\n",
                "        y.reset_index(drop=True, inplace=True)\n",
                "        df_scaled = pd.concat([X_scaled, y], axis=1)\n",
                "    else:\n",
                "        df_scaled = X_scaled\n",
                "\n",
                "    print(\"    Data standardized.\")\n",
                "    \n",
                "    # Output directory for this method\n",
                "    output_dir = f'../data/synthetic/{method}'\n",
                "    os.makedirs(output_dir, exist_ok=True)\n",
                "\n",
                "    # Detect Metadata on Scaled Data\n",
                "    metadata = SingleTableMetadata()\n",
                "    metadata.detect_from_dataframe(data=df_scaled)\n",
                "    \n",
                "    # Helper function to inverse transform and save\n",
                "    def inverse_transform_and_save(synthetic_data, filename, scaler, target_col, y_original=None):\n",
                "        if target_col in synthetic_data.columns:\n",
                "            X_syn = synthetic_data.drop(columns=[target_col])\n",
                "            y_syn = synthetic_data[target_col]\n",
                "        else:\n",
                "            X_syn = synthetic_data\n",
                "            y_syn = None\n",
                "            \n",
                "        # Inverse transform features\n",
                "        X_syn_inv = pd.DataFrame(scaler.inverse_transform(X_syn), columns=X_syn.columns)\n",
                "        \n",
                "        # Recombine\n",
                "        if y_syn is not None:\n",
                "            X_syn_inv.reset_index(drop=True, inplace=True)\n",
                "            y_syn.reset_index(drop=True, inplace=True)\n",
                "            df_syn_inv = pd.concat([X_syn_inv, y_syn], axis=1)\n",
                "        else:\n",
                "            df_syn_inv = X_syn_inv\n",
                "            \n",
                "        df_syn_inv.to_csv(filename, index=False)\n",
                "    \n",
                "    # --- CTGAN ---\n",
                "    print(f\"  > Generating CTGAN for {method}...\")\n",
                "    try:\n",
                "        ctgan = CTGANSynthesizer(metadata, epochs=300, verbose=True)\n",
                "        ctgan.fit(df_scaled)\n",
                "        synthetic_ctgan = ctgan.sample(num_rows=len(df))\n",
                "        \n",
                "        inverse_transform_and_save(synthetic_ctgan, f'{output_dir}/uc_diagnostics_ctgan.csv', scaler, target_col)\n",
                "        print(\"    CTGAN Saved (Standardized -> Generated -> Inverse Transformed).\")\n",
                "    except Exception as e:\n",
                "        print(f\"    CTGAN Failed: {e}\")\n",
                "    \n",
                "    # --- TVAE ---\n",
                "    print(f\"  > Generating TVAE for {method}...\")\n",
                "    try:\n",
                "        tvae = TVAESynthesizer(metadata, epochs=300, verbose=True)\n",
                "        tvae.fit(df_scaled)\n",
                "        synthetic_tvae = tvae.sample(num_rows=len(df))\n",
                "        \n",
                "        inverse_transform_and_save(synthetic_tvae, f'{output_dir}/uc_diagnostics_tvae.csv', scaler, target_col)\n",
                "        print(\"    TVAE Saved (Standardized -> Generated -> Inverse Transformed).\")\n",
                "    except Exception as e:\n",
                "        print(f\"    TVAE Failed: {e}\")\n",
                "    \n",
                "    # --- ADASYN ---\n",
                "    print(f\"  > Generating ADASYN for {method}...\")\n",
                "    try:\n",
                "        if y is None or y.isnull().any():\n",
                "             print(\"    ADASYN Skipping: Target column missing or contains NaNs.\")\n",
                "        else:\n",
                "            # ADASYN on Scaled X and original y\n",
                "            adasyn = ADASYN(sampling_strategy='not majority', random_state=42)\n",
                "            X_res, y_res = adasyn.fit_resample(X_scaled, y)\n",
                "            \n",
                "            synthetic_adasyn = pd.concat([X_res, y_res], axis=1)\n",
                "            \n",
                "            inverse_transform_and_save(synthetic_adasyn, f'{output_dir}/uc_diagnostics_adasyn.csv', scaler, target_col)\n",
                "            print(f\"    ADASYN Saved (Standardized -> Generated -> Inverse Transformed). New shape: {synthetic_adasyn.shape}\")\n",
                "    except Exception as e:\n",
                "        print(f\"    ADASYN Failed: {e}\")\n",
                "\n",
                "print(\"\\nAll synthetic data generation tasks completed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "uc_experiment",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
